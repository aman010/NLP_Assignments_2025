{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd76434d-0f33-4de7-8666-c3a669033d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-02 10:27:03.867084: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740911223.888524 3842443 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740911223.895306 3842443 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-02 10:27:03.919593: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#!pip install tf-keras\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, \n",
    "    AutoTokenizer, \n",
    "    HfArgumentParser, \n",
    "    TrainingArguments\n",
    ")\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d84c239c-a2de-4c28-b118-255ca065386f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset summarize_from_feedback (/home/jupyter-st125490/.cache/huggingface/datasets/openai___summarize_from_feedback/comparisons/0.0.0/483f970ceb55b926b0a087ef4f678ab1b089bc8174a107a452c6152e88af7ff0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1893dd3fa0c4642b7eef3686b3b0d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['info', 'summaries', 'choice', 'worker', 'batch', 'split', 'extra'],\n",
      "        num_rows: 92858\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['info', 'summaries', 'choice', 'worker', 'batch', 'split', 'extra'],\n",
      "        num_rows: 86086\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the P3 dataset\n",
    "dataset = load_dataset(\"openai/summarize_from_feedback\", \"comparisons\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5273031b-1bf4-4366-a20a-e0ec42477772",
   "metadata": {},
   "source": [
    "* OpenAI has made available a dataset that contains human preferences for generated text.\n",
    "* This dataset is specifically focused on training reinforcement learning models with human feedback.\n",
    "* It's smaller than P3 and might be more manageable.\n",
    "\n",
    "**Preprocessing:**\n",
    "**We can preprocess this dataset similarly by extracting prompts, responses, and human feedback**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3849252f-8677-4da3-9668-58afd72fc75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(sample_):\n",
    "    prompt = sample_['info']['post']\n",
    "    response_1 = sample_['summaries'][0]['text']\n",
    "    response_2 = sample_['summaries'][1]['text']\n",
    "    preference = sample_['choice']\n",
    "    return { 'prompt': prompt,\n",
    "            'response_1': response_1,\n",
    "            'response_2': response_2,\n",
    "            'preference': preference}\n",
    "\n",
    "# small_train_dataset = processed_data.select(range(int(len() * 0.2))) \n",
    "sample = [dataset['train'][i] for i in range(0, 500)]\n",
    "sample_eval = [dataset['validation'][i] for i in range(0, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbef3b54-6c25-4ac3-8c2f-c4314c383ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = {'prompt': [], 'label':[],'preference':[]}\n",
    "for s in sample:\n",
    "    r = extract_data(sample_=s)\n",
    "    sam['prompt'].append(r['prompt'])\n",
    "    sam['label'].append([r['response_1'], r['response_2']])\n",
    "    sam['preference'].append(r['preference'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aead145a-8ebe-42f3-a20c-e70b94aa8e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_eval  = {'prompt': [], 'label':[],'preference':[]}\n",
    "for s in sample_eval:\n",
    "    r = extract_data(sample_=s)\n",
    "    sam_eval['prompt'].append(r['prompt'])\n",
    "    sam_eval['label'].append([r['response_1'], r['response_2']])\n",
    "    sam_eval['preference'].append(r['preference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5d1845d-c358-4146-8a09-6a9f39b24ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x=pd.DataFrame(sam)\n",
    "t = pd.DataFrame(sam_eval)\n",
    "data = x.assign(label=x['label']).explode(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3a5fd8f-f89a-4c25-b2ef-9b4b9687f5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "model_name = \"gpt2\"  # or any other pre-trained model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7390216c-75bf-49b7-ada2-c8324701b4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>label</th>\n",
       "      <th>preference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>Mum is mad at me for not flying on my own tri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>I have made sure my mother is comfortable wit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>I have made sure my mother is comfortable wit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>mum isn't speaking to me because I booked a f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>mum isn't speaking to me because I booked a f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  My boyfriend and I are long distance. We have ...   \n",
       "1  My boyfriend and I are long distance. We have ...   \n",
       "2  My boyfriend and I are long distance. We have ...   \n",
       "3  My boyfriend and I are long distance. We have ...   \n",
       "4  My boyfriend and I are long distance. We have ...   \n",
       "\n",
       "                                               label  preference  \n",
       "0   Mum is mad at me for not flying on my own tri...           1  \n",
       "1   I have made sure my mother is comfortable wit...           1  \n",
       "2   I have made sure my mother is comfortable wit...           1  \n",
       "3   mum isn't speaking to me because I booked a f...           1  \n",
       "4   mum isn't speaking to me because I booked a f...           0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reset_index(drop=True, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "919b3291-fe9e-4358-ac23-637ad7325cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_len = 512\n",
    "# def preprocess_and_tokenize(batch):\n",
    "#     # Extracting the prompt and responses\n",
    "#     prompts = batch['info']\n",
    "#     choice = batch['choice']\n",
    "#     # print(\"***************************\",batch['summaries'])\n",
    "#     # print(\"*****************************\",batch['summaries'][1])\n",
    "#     # responses_1 = batch['summaries'][0]  # human response\n",
    "#     # responses_2 = batch['summaries'][1]  # GPT response\n",
    "\n",
    "#     # Initialize lists to store tokenized outputs\n",
    "#     input_ids = []\n",
    "#     attention_masks = []\n",
    "#     labels = []\n",
    "#     pref = []\n",
    "#     # Loop over each example in the batch\n",
    "#     for i in range(len(prompts)):\n",
    "#         prompt = prompts[i].get('post', None)  # Extract 'post' from the 'info' field\n",
    "#         if prompt is None or len(prompt) == 0:\n",
    "#             prompt = '<|endoftext|>'\n",
    "#             print(i)\n",
    "#             print(batch['split'])\n",
    "#         response_1 = batch['summaries'][i][0]['text']  # human-generated text\n",
    "#         if response_1 is None:\n",
    "#             # response_1 = '<|endoftext|>'\n",
    "#             response_1 = batch['summaries'][i][0]['EDIT']\n",
    "#             # print(i)\n",
    "#             # print(batch['split'])\n",
    "#         if len(response_1) == 0:\n",
    "#             response_1 = '<|endoftext|>'\n",
    "#         response_2 = batch['summaries'][i][1]['text']  # GPT-generated text\n",
    "#         if response_2 is None:\n",
    "#             # response_2 = '<|endoftext>'\n",
    "#             response_2 = batch['summaries'][i][0]['EDIT']\n",
    "#         if len(response_2) == 0:\n",
    "#             response_2 = '<|endoftext|>'\n",
    "#             # print(i)\n",
    "#             # print(batch['split'])\n",
    "#         # Tokenizing the prompt (max length = 1000)\n",
    "#         # few of the last rows are null in validation set\n",
    "#         prompt_encoding = tokenizer(text=prompt, truncation=True, padding=\"max_length\", max_length=512, return_tensors = \"pt\")\n",
    "        \n",
    "#         # Tokenizing both responses (max length = 512 for responses to ensure they are short)\n",
    "#         response_1_encoding = tokenizer(text=response_1, truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
    "#         response_2_encoding = tokenizer(text=response_2, truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
    "#         # Append tokenized results\n",
    "#         input_ids.append(prompt_encoding['input_ids'].squeeze(0).tolist())\n",
    "#         attention_masks.append(prompt_encoding['attention_mask'].squeeze(0).tolist())\n",
    "#         labels.append([response_1_encoding['input_ids'].squeeze(0).tolist(), response_2_encoding['input_ids'].squeeze(0).tolist()])\n",
    "#         # labels.append()\n",
    "#         pref.append(float(choice[i]))\n",
    "\n",
    "        \n",
    "#     return {\n",
    "#         'input_ids': input_ids,\n",
    "#         'attention_mask': attention_masks,\n",
    "#         'labels': labels,\n",
    "#         'preferences': pref\n",
    "#     }\n",
    "\n",
    "# # Set pad token to eos token (this ensures padding will be handled by the tokenizer)\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# # Apply preprocessing to the validation dataset (with batched=True)\n",
    "# processed_data = dataset['train'].map(preprocess_and_tokenize, batched=True)\n",
    "# # processed_val_dataset = dataset['validation'].map(preprocess_and_tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1cbd8cf2-022f-4312-9707-fcea2e7a028d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>label</th>\n",
       "      <th>preference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>[ Mum is mad at me for not flying on my own tr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>[ I have made sure my mother is comfortable wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>[ mum isn't speaking to me because I booked a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My boyfriend and I are long distance. We have ...</td>\n",
       "      <td>[ Mum thought I was going to road trip with my...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My landlord left a falsified message taped to ...</td>\n",
       "      <td>[ My landlord is harassing me and my neighbour...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Ever since I hit puberty (when I was about nin...</td>\n",
       "      <td>[ My mom always asks me to put on \"modest\" clo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Ever since I hit puberty (when I was about nin...</td>\n",
       "      <td>[ My mom constantly asks me to cover my body w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Ever since I hit puberty (when I was about nin...</td>\n",
       "      <td>[ My mom always makes me cover up when around ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Ever since I hit puberty (when I was about nin...</td>\n",
       "      <td>[ My mom repeats the same phrases about me eve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Ever since I hit puberty (when I was about nin...</td>\n",
       "      <td>[ My mom always asks me to put on \"modest\" clo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt  \\\n",
       "0    My boyfriend and I are long distance. We have ...   \n",
       "1    My boyfriend and I are long distance. We have ...   \n",
       "2    My boyfriend and I are long distance. We have ...   \n",
       "3    My boyfriend and I are long distance. We have ...   \n",
       "4    My landlord left a falsified message taped to ...   \n",
       "..                                                 ...   \n",
       "995  Ever since I hit puberty (when I was about nin...   \n",
       "996  Ever since I hit puberty (when I was about nin...   \n",
       "997  Ever since I hit puberty (when I was about nin...   \n",
       "998  Ever since I hit puberty (when I was about nin...   \n",
       "999  Ever since I hit puberty (when I was about nin...   \n",
       "\n",
       "                                                 label  preference  \n",
       "0    [ Mum is mad at me for not flying on my own tr...           1  \n",
       "1    [ I have made sure my mother is comfortable wi...           1  \n",
       "2    [ mum isn't speaking to me because I booked a ...           0  \n",
       "3    [ Mum thought I was going to road trip with my...           0  \n",
       "4    [ My landlord is harassing me and my neighbour...           1  \n",
       "..                                                 ...         ...  \n",
       "995  [ My mom always asks me to put on \"modest\" clo...           1  \n",
       "996  [ My mom constantly asks me to cover my body w...           0  \n",
       "997  [ My mom always makes me cover up when around ...           1  \n",
       "998  [ My mom repeats the same phrases about me eve...           1  \n",
       "999  [ My mom always asks me to put on \"modest\" clo...           1  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c6dd126-1e17-4993-b05c-b9ecaa5010cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.DataFrame(processed_data)\n",
    "\n",
    "\n",
    "# Sample data (assuming it's in a pandas DataFrame)\n",
    "\n",
    "def tokenize_data_separately(df):\n",
    "    tokenized_data = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        prompt = row['prompt']\n",
    "        label = row['label']\n",
    "        preference = row['preference']\n",
    "\n",
    "        # Tokenize the prompt separately\n",
    "        prompt_tokens = tokenizer(prompt, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "        # Tokenize the label separately\n",
    "        response_1 = tokenizer(label[0], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "        response_2 = tokenizer(label[1], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "        tokenized_data.append({\n",
    "            'input_ids': prompt_tokens['input_ids'].squeeze(),  # Prompt token IDs\n",
    "            'attention_mask': prompt_tokens['attention_mask'].squeeze(),  # Prompt attention mask\n",
    "            'response_1': response_1['input_ids'].squeeze(),  # Label token IDs (as target)\n",
    "            'response_2': response_2['input_ids'].squeeze(),\n",
    "            'preference': preference  # Reward (preference)\n",
    "        })\n",
    "\n",
    "    return tokenized_data\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_data_train = tokenize_data_separately(x)\n",
    "tokenized_data_test = tokenize_data_separately(t)\n",
    "\n",
    "# Process the data\n",
    "# Inspect the tokenized data\n",
    "# for item in tokenized_data[:2]:  # Displaying the first 2 examples\n",
    "#     print(item)\n",
    "from datasets import Dataset\n",
    "# Convert the tokenized data into a Hugging Face Dataset\n",
    "dataset = Dataset.from_dict({\n",
    "    'input_ids': [item['input_ids'] for item in tokenized_data_train],\n",
    "    'attention_mask': [item['attention_mask'] for item in tokenized_data_train],\n",
    "    'response_1': [item['response_1'] for item in tokenized_data_train],\n",
    "    'response_2': [item['response_2'] for item in tokenized_data_train],\n",
    "    'preference': [item['preference'] for item in tokenized_data_train]\n",
    "})\n",
    "\n",
    "dataset_eval = Dataset.from_dict({\n",
    "    'input_ids': [item['input_ids'] for item in tokenized_data_test],\n",
    "    'attention_mask': [item['attention_mask'] for item in tokenized_data_test],\n",
    "    'response_1': [item['response_1'] for item in tokenized_data_test],\n",
    "    'response_2': [item['response_2'] for item in tokenized_data_test],\n",
    "    'preference': [item['preference'] for item in tokenized_data_test]\n",
    "})\n",
    "# Inspect the dataset\n",
    "# print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c0a5e24-353e-4176-8985-af293717f810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'response_1', 'response_2', 'preference'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d7327c46-0ba6-4b3a-917b-b440cde9bfed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'response_1', 'response_2', 'preference'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1e32912-d1a6-427b-827b-6b744d465548",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPOTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        # ... (rest of the method remains the same)\n",
    "\n",
    "        return (loss, outputs_1) if return_outputs else loss\n",
    "\n",
    "    def log(self, logs):\n",
    "        if self.state.epoch is not None:\n",
    "            logs[\"epoch\"] = self.state.epoch\n",
    "        if self.state.global_step is not None:\n",
    "            logs[\"step\"] = self.state.global_step\n",
    "        if self.state.max_steps is not None:\n",
    "            logs[\"max_steps\"] = self.state.max_steps\n",
    "\n",
    "        # Add validation metrics logging\n",
    "        if \"eval_loss\" in logs:\n",
    "            self.control = self.callback_handler.on_log(self.args, self.state, self.control, logs)\n",
    "\n",
    "    def evaluation_loop(\n",
    "        self,\n",
    "        dataloader,\n",
    "        description,\n",
    "        prediction_loss_only=None,\n",
    "        ignore_keys=None,\n",
    "        metric_key_prefix=\"eval\",\n",
    "    ):\n",
    "        evaluation_outputs = super().evaluation_loop(\n",
    "            dataloader,\n",
    "            description=description,\n",
    "            prediction_loss_only=prediction_loss_only,\n",
    "            ignore_keys=ignore_keys,\n",
    "            metric_key_prefix=metric_key_prefix,\n",
    "        )\n",
    "\n",
    "        # Log validation metrics\n",
    "        logs = {}\n",
    "        logs[f\"{metric_key_prefix}_loss\"] = evaluation_outputs.loss\n",
    "        logs[f\"{metric_key_prefix}_accuracy\"] = evaluation_outputs.metrics[\"accuracy\"]\n",
    "        self.log(logs)\n",
    "\n",
    "        return evaluation_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76c9f538-7af7-4000-97c1-5c40b2e722ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from time import time\n",
    "\n",
    "class DPOTrainer(Trainer):\n",
    "    # def __init__(self, *args, **kwargs):\n",
    "    #     super(DPOTrainer, self).__init__(*args, **kwargs)\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        # Extract inputs\n",
    "        # dict_keys(['input_ids', 'attention_mask', 'response_1', 'response_2', 'preference'])\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        labels = inputs['response_1']  # Chosen response\n",
    "        labels_2 = inputs['response_2']  # Rejected response\n",
    "        preferences = inputs['preference']  # Preference (1 for chosen, 0 for rejected)\n",
    "\n",
    "        # Forward pass for the chosen response\n",
    "        outputs_1 = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss_1 = outputs_1.loss\n",
    "\n",
    "        # Forward pass for the rejected response\n",
    "        outputs_2 = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels_2)\n",
    "        loss_2 = outputs_2.loss\n",
    "        # Preferences tensor with batch size of 8\n",
    "\n",
    "\n",
    "        # DPO loss calculation: minimize the loss for the chosen response\n",
    "        # and maximize the loss for the rejected response\n",
    "        preference_loss = (preferences * loss_1) + ((1 - preferences) * loss_2)\n",
    "\n",
    "        # Return the combined loss\n",
    "        loss = preference_loss.mean()\n",
    "        \n",
    "        return (loss, outputs_1) if return_outputs else loss\n",
    "\n",
    "    # def log(self, logs, time):\n",
    "    #     if self.state.epoch is not None:\n",
    "    #         logs[\"epoch\"] = self.state.epoch\n",
    "    #     if self.state.global_step is not None:\n",
    "    #         logs[\"step\"] = self.state.global_step\n",
    "    #     if self.state.max_steps is not None:\n",
    "    #         logs[\"max_steps\"] = self.state.max_steps\n",
    "\n",
    "    #     # Add validation metrics logging\n",
    "    #     if \"eval_loss\" in logs:\n",
    "    #         self.control = self.callback_handler.on_log(self.args, self.state, self.control, logs)\n",
    "\n",
    "    # def log(self,logs, start_time):\n",
    "    #     if self.state.epoch is not None:\n",
    "    #         logs['epoch'] = self.state.epoch\n",
    "    #     if self.state.global_step is not None:\n",
    "    #         logs['step'] = self.state.global_step\n",
    "    #     if self.state.max_steps is not None:\n",
    "    #         logs['max_steps'] = self.state.max_steps\n",
    "\n",
    "    #     if \"eval_loss\" in logs:\n",
    "    #         self.control = self.callback_handler.on_log(self.args, self.state ,self.control, logs)\n",
    "    #     print(\"validation\", logs)\n",
    "\n",
    "    def evaluation_loop(\n",
    "    self,\n",
    "    dataloader,\n",
    "    description,\n",
    "    prediction_loss_only=None,\n",
    "    ignore_keys=None,\n",
    "    metric_key_prefix=\"eval\",\n",
    "    ):\n",
    "        evaluation_outputs = super().evaluation_loop(\n",
    "            dataloader,\n",
    "            description=description,\n",
    "            prediction_loss_only=prediction_loss_only,\n",
    "            ignore_keys=ignore_keys,\n",
    "            metric_key_prefix=metric_key_prefix,\n",
    "        )\n",
    "        \n",
    "        # Calculate the loss separately\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            inputs = batch\n",
    "            loss = self.compute_loss(self.model, inputs)\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # Calculate the average loss\n",
    "        average_loss = total_loss / len(dataloader)\n",
    "        print(\"Validation_loss\",average_loss)        # Log the evaluation metrics\n",
    "        logs = {}\n",
    "        logs[f\"{metric_key_prefix}_loss\"] = average_loss\n",
    "        # logs[f\"{metric_key_prefix}_accuracy\"] = \n",
    "        # start_time = time()\n",
    "        # self.log(logs, start_time)\n",
    "    \n",
    "        return evaluation_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6489f04d-d218-41cc-9ac1-210a374702dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "per_device_train_batch_size = 2\n",
    "gradient_accumulation_steps = 1\n",
    "max_length= 512 \n",
    "max_prompt_length = 128 \n",
    "max_target_length =128 \n",
    "label_pad_token_id = 100\n",
    "max_steps = 1000\n",
    "# instrumentation\n",
    "sanity_check = True\n",
    "report_to = None\n",
    "gradient_checkpointing = None\n",
    "beta = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc095299-837f-415d-a025-bda9f1b4aafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st125490/.local/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    # Batch size for training on each device (e.g., GPU)\n",
    "    max_steps=max_steps,\n",
    "    remove_unused_columns=False,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_first_step=True,\n",
    "    logging_steps=100,  # match results in blog post\n",
    "    eval_steps=100,\n",
    "    output_dir=\"./test\",\n",
    "    optim=\"rmsprop\",\n",
    "    warmup_steps=150,\n",
    "    report_to=report_to,\n",
    "    bf16=True,\n",
    "    gradient_checkpointing=gradient_checkpointing,\n",
    "    num_train_epochs=3,  # Number of training epochs, \n",
    "\n",
    "    # TODO: uncomment that on the next transformers release\n",
    "    # gradient_checkpointing_kwargs=gradient_checkpointing_kwargs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c354a28a-72cb-4ce7-a52c-dfed073ec89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_3842443/2248676155.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `DPOTrainer.__init__`. Use `processing_class` instead.\n",
      "  dpo_trainer = DPOTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 10:52, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.439900</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.365100</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.349200</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.337400</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.323900</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.311700</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.318300</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.302700</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation_loss 0.5874071642756462\n",
      "Validation_loss 0.5894651040434837\n",
      "Validation_loss 0.5628296360373497\n",
      "Validation_loss 0.5718576163053513\n",
      "Validation_loss 0.5793038532137871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st125490/.local/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation_loss 0.5730819553136826\n",
      "Validation_loss 0.5718317925930023\n",
      "Validation_loss 0.567954458296299\n",
      "Validation_loss 0.5693484768271446\n",
      "Validation_loss 0.5691354125738144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=0.34970706948637964, metrics={'train_runtime': 653.433, 'train_samples_per_second': 4.591, 'train_steps_per_second': 1.53, 'total_flos': 782569635840000.0, 'train_loss': 0.34970706948637964, 'epoch': 5.9880239520958085})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, gc\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.reset_accumulated_memory_stats()\n",
    "gc.collect()\n",
    "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
    "# Set the environment variable to specify the GPUs (1, 2, and 3)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3\"\n",
    "# PYTORCH_CUDA_ALLOC_CONF={'expandable_segments':True}\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset = dataset_eval,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "dpo_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183575c4-d50e-46c2-82a8-ce7dec6090ff",
   "metadata": {},
   "source": [
    "**Tried to find Validation Loss Issue but fail to do so may be inference might give more insight.**\n",
    "**Validation loss is not stable due to low sample size, but keep it smaller because of resource limitation, for two summary generations it works below random**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae94023f-44a1-4ee2-9d62-fe6273169092",
   "metadata": {},
   "source": [
    "## Inference Process in RLHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d0d048a-7a79-4eb1-b2eb-3a7092584162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset summarize_from_feedback (/home/jupyter-st125490/.cache/huggingface/datasets/openai___summarize_from_feedback/comparisons/0.0.0/483f970ceb55b926b0a087ef4f678ab1b089bc8174a107a452c6152e88af7ff0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6910ffd9114770b8dba131c94eb67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Using a throwaway since I don't want this tied to my main account. Anyways, I have a friend whom I haven't talked to in a year. I recently made a new facebook, added her (which she accepted), and sent her a message. We've known each other since high school, so about 5 years now.\\n\\nI asked her if she would like to meet up to catch up on things, she said she might be free this week (that was last friday). I told her just message me with a convenient time and she said sure. Now, I'm close to positive she won't respond again, which is fine, but I've been trying to mend a lot of friendships. I've 'restored' 3 or 4 now.\\n\\nI'm trying to change my lifestyle, and 'old me' would have sent a couple messages on monday/tuesday, but I don't want to sound creepy or needy. I genuinely want to send a thought out apology.\\n\\nI just need some help on getting it across in a decent way. Even if she just says she doesn't want to be my friend, I just want to send it as a peace of mind. I've restored 3 good friendships so far by 'speaking from the heart' but it was a fairly short thing since I had just fallen out of contact with them.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import numpy as np\n",
    "# Load trained model and tokenizer\n",
    "\n",
    "\n",
    "dataset_valid = load_dataset(\"openai/summarize_from_feedback\", \"comparisons\")\n",
    "idx =np.random.choice(len(dataset_valid['validation']))\n",
    "Input_text=dataset_valid['validation'][idx]['info']['post']\n",
    "dataset_valid['validation'][idx]['info']['post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42d758c3-0455-4660-9dfc-00a0d6bf1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"\n",
    "My boyfriend and I are long distance. We have been trying to make it work, but we struggle with time zones, \n",
    "communication, and missing each other. We try to visit every few months, but it's always hard being apart. \n",
    "We talk every day, but sometimes I feel disconnected because of the distance. \n",
    "We've been planning for the future, and I'm hopeful that we will eventually live closer, but right now, it feels like a lot of work.\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "acda8e41-a3e6-490d-a4f5-fe45e7e2a652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: Using a throwaway since I don't want this tied to my main account. Anyways, I have a friend whom I haven't talked to in a year. I recently made a new facebook, added her (which she accepted), and sent her a message. We've known each other since high school, so about 5 years now.\n",
      "\n",
      "I asked her if she would like to meet up to catch up on things, she said she might be free this week (that was last friday). I told her just message me with a convenient time and she said sure. Now, I'm close to positive she won't respond again, which is fine, but I've been trying to mend a lot of friendships. I've 'restored' 3 or 4 now.\n",
      "\n",
      "I'm trying to change my lifestyle, and 'old me' would have sent a couple messages on monday/tuesday, but I don't want to sound creepy or needy. I genuinely want to send a thought out apology.\n",
      "\n",
      "I just need some help on getting it across in a decent way. Even if she just says she doesn't want to be my friend, I just want to send it as a peace of mind. I've restored 3 good friendships so far by 'speaking from the heart' but it was a fairly short thing since I had just fallen out of contact with them. That\n",
      "Response 2: Using a throwaway since I don't want this tied to my main account. Anyways, I have a friend whom I haven't talked to in a year. I recently made a new facebook, added her (which she accepted), and sent her a message. We've known each other since high school, so about 5 years now.\n",
      "\n",
      "I asked her if she would like to meet up to catch up on things, she said she might be free this week (that was last friday). I told her just message me with a convenient time and she said sure. Now, I'm close to positive she won't respond again, which is fine, but I've been trying to mend a lot of friendships. I've 'restored' 3 or 4 now.\n",
      "\n",
      "I'm trying to change my lifestyle, and 'old me' would have sent a couple messages on monday/tuesday, but I don't want to sound creepy or needy. I genuinely want to send a thought out apology.\n",
      "\n",
      "I just need some help on getting it across in a decent way. Even if she just says she doesn't want to be my friend, I just want to send it as a peace of mind. I've restored 3 good friendships so far by 'speaking from the heart' but it was a fairly short thing since I had just fallen out of contact with them. Also\n",
      "Response 3: Using a throwaway since I don't want this tied to my main account. Anyways, I have a friend whom I haven't talked to in a year. I recently made a new facebook, added her (which she accepted), and sent her a message. We've known each other since high school, so about 5 years now.\n",
      "\n",
      "I asked her if she would like to meet up to catch up on things, she said she might be free this week (that was last friday). I told her just message me with a convenient time and she said sure. Now, I'm close to positive she won't respond again, which is fine, but I've been trying to mend a lot of friendships. I've 'restored' 3 or 4 now.\n",
      "\n",
      "I'm trying to change my lifestyle, and 'old me' would have sent a couple messages on monday/tuesday, but I don't want to sound creepy or needy. I genuinely want to send a thought out apology.\n",
      "\n",
      "I just need some help on getting it across in a decent way. Even if she just says she doesn't want to be my friend, I just want to send it as a peace of mind. I've restored 3 good friendships so far by 'speaking from the heart' but it was a fairly short thing since I had just fallen out of contact with them. That\n",
      "Response 4: Using a throwaway since I don't want this tied to my main account. Anyways, I have a friend whom I haven't talked to in a year. I recently made a new facebook, added her (which she accepted), and sent her a message. We've known each other since high school, so about 5 years now.\n",
      "\n",
      "I asked her if she would like to meet up to catch up on things, she said she might be free this week (that was last friday). I told her just message me with a convenient time and she said sure. Now, I'm close to positive she won't respond again, which is fine, but I've been trying to mend a lot of friendships. I've 'restored' 3 or 4 now.\n",
      "\n",
      "I'm trying to change my lifestyle, and 'old me' would have sent a couple messages on monday/tuesday, but I don't want to sound creepy or needy. I genuinely want to send a thought out apology.\n",
      "\n",
      "I just need some help on getting it across in a decent way. Even if she just says she doesn't want to be my friend, I just want to send it as a peace of mind. I've restored 3 good friendships so far by 'speaking from the heart' but it was a fairly short thing since I had just fallen out of contact with them. If\n",
      "Response 5: Using a throwaway since I don't want this tied to my main account. Anyways, I have a friend whom I haven't talked to in a year. I recently made a new facebook, added her (which she accepted), and sent her a message. We've known each other since high school, so about 5 years now.\n",
      "\n",
      "I asked her if she would like to meet up to catch up on things, she said she might be free this week (that was last friday). I told her just message me with a convenient time and she said sure. Now, I'm close to positive she won't respond again, which is fine, but I've been trying to mend a lot of friendships. I've 'restored' 3 or 4 now.\n",
      "\n",
      "I'm trying to change my lifestyle, and 'old me' would have sent a couple messages on monday/tuesday, but I don't want to sound creepy or needy. I genuinely want to send a thought out apology.\n",
      "\n",
      "I just need some help on getting it across in a decent way. Even if she just says she doesn't want to be my friend, I just want to send it as a peace of mind. I've restored 3 good friendships so far by 'speaking from the heart' but it was a fairly short thing since I had just fallen out of contact with them. However\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# # Input text for generating multiple responses\n",
    "# input_text = \"My boyfriend and I are long distance. We have...\"\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
    "\n",
    "# Load the model and tokenizer\n",
    "# model = GPT2LMHeadModel.from_pretrained('gpt2').cuda()\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "# Tokenize input\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "inputs = tokenizer(Input_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "# Set the seed globally for PyTorch\n",
    "seed = random.randint(0, 2**32 - 1)  # Random seed\n",
    "torch.manual_seed(seed)  # For CPU operations\n",
    "torch.cuda.manual_seed_all(seed)  # For GPU operations\n",
    "\n",
    "responses = model.generate(\n",
    "    inputs[\"input_ids\"].cuda(),\n",
    "    max_length=281,\n",
    "    num_return_sequences=5,  # Generate multiple responses\n",
    "    temperature=1.5,  # Increase temperature for randomness\n",
    "    top_p=0.9,  # Use nucleus sampling (top_p)\n",
    "    top_k=50,  # Sampling from top 50 tokens\n",
    "    do_sample=True,  # Enable sampling\n",
    "    repetition_penalty=1.5,  # Penalize repetitive words\n",
    "    no_repeat_ngram_size=3,  # Prevent repeating 3-grams\n",
    ").cuda()\n",
    "# Decode and print the generated responses\n",
    "decoded_responses = [tokenizer.decode(response, skip_special_tokens=True) for response in responses]\n",
    "\n",
    "for idx, response in enumerate(decoded_responses):\n",
    "    print(f\"Response {idx+1}: {response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9adc72-ffc3-4476-9d73-2e6820c7e51b",
   "metadata": {},
   "source": [
    "**Now we have generated the sample we can further perform RLHF inference by assuming the feedback and for each of the response and ranking each of the response this way DPO will optimize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e7108dad-022a-41ab-b9f6-7d2ecf1759f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81965c9d-5ef4-4369-88cd-8b22e259e999",
   "metadata": {},
   "source": [
    "## Few Model Performance Experements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed698ec9-ad2e-46c9-888d-6a0307c6195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    # Batch size for training on each device (e.g., GPU)\n",
    "    max_steps=max_steps,\n",
    "    remove_unused_columns=False,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    learning_rate=0.0005,\n",
    "    eval_strategy=\"steps\",\n",
    "    logging_first_step=True,\n",
    "    logging_steps=100,  # match results in blog post\n",
    "    eval_steps=100,\n",
    "    output_dir=\"./test\",\n",
    "    optim=\"adamw_hf\",\n",
    "    warmup_steps=150,\n",
    "    report_to=\"tensorboard\",\n",
    "    bf16=True,\n",
    "    gradient_checkpointing=gradient_checkpointing,\n",
    "    num_train_epochs=3,  # Number of training epochs\n",
    "\n",
    "    # TODO: uncomment that on the next transformers release\n",
    "    # gradient_checkpointing_kwargs=gradient_checkpointing_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae338f67-fdd8-4fbe-8632-1f15f0f13cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3687305/1875480854.py:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `DPOTrainer.__init__`. Use `processing_class` instead.\n",
      "  super(DPOTrainer, self).__init__(*args, **kwargs)\n",
      "/home/jupyter-st125490/.local/lib/python3.12/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/jupyter-st125490/.local/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 17:54, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.042800</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.349800</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.306200</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.277200</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.257300</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.193500</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.157300</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.146900</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-st125490/.local/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=0.32084336376190187, metrics={'train_runtime': 1075.7862, 'train_samples_per_second': 3.718, 'train_steps_per_second': 0.93, 'total_flos': 1045168128000000.0, 'train_loss': 0.32084336376190187, 'epoch': 4.0})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_trainer = DPOTrainer(\n",
    "    model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset = dataset_eval,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "dpo_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b955e0-81f9-4177-9df6-f91a1d2ea36d",
   "metadata": {},
   "source": [
    "**From above generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "198d036e-999f-4fbb-a901-9eaf93aac732",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6669aba4-8ae0-488a-890b-9a38abfc345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'DPO-GPT2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79f87c24-2d00-4e5a-8901-992cbfad7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token_id = tokenizer.pad_token_id\n",
    "padding_length = 1\n",
    "if padding_length > 0:\n",
    "    input_ids = torch.cat([inputs['input_ids'], torch.full((inputs['input_ids'].shape[0], padding_length), pad_token_id)], dim=1)\n",
    "attention_mask = torch.cat([inputs['attention_mask'], torch.zeros((inputs['attention_mask'].shape[0], padding_length), dtype=torch.long)], dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d8d9c24-17ee-4956-8f67-f546d0a82d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([1, 1, 281]),\n",
       " 'attention_mask': torch.Size([1, 1, 281]),\n",
       " 'response_1': torch.Size([1, 281]),\n",
       " 'response_2': torch.Size([1, 281]),\n",
       " 'preference': tensor([0, 1])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'input_ids':input_ids.unsqueeze(0).cuda().size(), \n",
    " 'attention_mask':attention_mask.unsqueeze(0).cuda().size(),\n",
    " 'response_1':responses[0].unsqueeze(0).cuda().size(),\n",
    "'response_2':responses[1].unsqueeze(0).cuda().size(),\n",
    "'preference':torch.tensor([0,1], dtype = torch.long)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb96e991-7783-4476-b10a-6e01552cf308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.8830, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_trainer.compute_loss(model.to(\"cuda:0\"),{'input_ids':input_ids[0].unsqueeze(1).cuda(), \n",
    " 'attention_mask':attention_mask[0].unsqueeze(0).cuda(),\n",
    " 'response_1':responses[0].unsqueeze(0).cuda(),\n",
    "'response_2':responses[1].unsqueeze(0).cuda(),\n",
    "'preference':torch.tensor([0,1], dtype = torch.long).cuda()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b39d201-a033-4925-b094-191194c8f0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.8860, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_trainer.compute_loss(model.to(\"cuda:0\"),{'input_ids':input_ids[0].unsqueeze(1).cuda(), \n",
    " 'attention_mask':attention_mask[0].unsqueeze(0).cuda(),\n",
    " 'response_1':responses[1].unsqueeze(0).cuda(),\n",
    "'response_2':responses[2].unsqueeze(0).cuda(),\n",
    "'preference':torch.tensor([1,1], dtype = torch.long).cuda()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0cc92cc4-2c13-4cb9-ae49-a1e6b1c208c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.8841, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_trainer.compute_loss(model.to(\"cuda:0\"),{'input_ids':input_ids[0].unsqueeze(1).cuda(), \n",
    " 'attention_mask':attention_mask[0].unsqueeze(0).cuda(),\n",
    " 'response_1':responses[3].unsqueeze(0).cuda(),\n",
    "'response_2':responses[4].unsqueeze(0).cuda(),\n",
    "'preference':torch.tensor([0,0], dtype = torch.long).cuda()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5dd39e36-7d60-4011-b094-3806b9462eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reward loss</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.2984</td>\n",
       "      <td>0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.2947</td>\n",
       "      <td>1,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.2947</td>\n",
       "      <td>3,4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Reward loss Dataset\n",
       "0      6.2984     0,0\n",
       "1      6.2947     1,2\n",
       "2      6.2947     3,4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "v=pd.DataFrame(columns =['Reward loss', 'Dataset'])\n",
    "v['Reward loss'] = ['6.2984', '6.2947', '6.2947']\n",
    "v['Dataset'] = ['0,0','1,2', '3,4']\n",
    "display(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d58fa0-0fe5-412f-ae37-743ba13523c5",
   "metadata": {},
   "source": [
    "**Where 0 and 1 is the sentence generated**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba0e16e-211d-4c94-ae8e-b60c62ac904e",
   "metadata": {},
   "source": [
    "**Observation challanges and mistakes**\n",
    "\n",
    "* our objective was to make summarization model\n",
    "* we are using feedback_suumarization dataset\n",
    "* each prompt have multiple responses, each and each set of reponse have preference score 1 or 0 which is human in loop \n",
    "* our objective was to score more and better generalized model\n",
    "* now at the end with the given provied time we tried to make things possible and due to shortage of time could not make changes\n",
    "* i realied that GPT-2 is not suitable for summarization\n",
    "* we named it text generation or where given the input the model tend to generate text as per the genrated text above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
